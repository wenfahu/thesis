\chapter{总结与展望}

\section{论文工作总结}

本文主要研究整数型Winograd 卷积在ARM CPU上的高效实现，从而加速卷积神经网络在ARM上的运行效率。对于
智能应用在移动和边缘设备的部署具备着积极的意义。

移动设备上运行卷积网络当前最大的痛点在于卷积网络庞大的计算量与移动设备有限的计算能力之间的矛盾。
而同时，尽管模型量化方法已经存在了众多研究，但在支持量化网络模型在移动设备上的高效执行方面，业界
依然存在着相当的空白。本文针对上述的难点和痛点，将目前已经的计算复杂度最低的卷积算法针对ARM 设备
硬件特性，实现改造调整，并且结合线性量化策略，实现卷积网络中端到端的整数计算流程。对比于现有的移动端
框架对于卷积网络的实现，取得了相对的效率提升。以下是本文完成的主要工作内容：

\begin{itemize}
    \item Winograd 算法可以在广泛存在移动端和边缘计算设备上的ARM CPU上实现计算复杂度的降低和计算功耗的节省。
    Winograd 卷积运行的过程中有着输入变换和输出变换带来的额外开销，Winograd 卷积主要是加速效果来自于减少了
    乘法操作，因而这二者带来的开销需要通过GEMM计算来做摊销。
    所以在Winograd卷积的运行中可见，卷积的输出通道数越大，卷积的加速效果越明显越接近于Winograd卷积加速的理论值。
    文中针对于Arm Cortex A设备，通过空间局部区域多通道处理方法，高效的使用ARMv8-A NEON SIMD 指令，
    实现了移动/嵌入式场景下内存有限， 计算能力受限的状态下，Winograd 卷积的高效实现。
    对每个卷积输出的子区域，独立并行计算这一多通道区域的输入变换， 矩阵乘法和输出变换。输入变换的
    16个空间位置的结果 被scatter到16 组Winograd域中的GEMM计算中，之后并行执行这16组GEMM，即输入变换
    和权重变换的结果的乘积，最后从对应的16组GEMM中 gather 到每个区域对应的结果，执行输出变换，将
    最后的结果变换回空间域的值并作输出。并且在data layout，权重预处理，中间结果存储（store）等等方面
    为此算法的实现和ARM Cortex A架构的特征做了设计。 
    \item 结合上面的整数卷积方法实现，本文应用静态线性量化策略，使用整数模拟逼近浮点数计算，
    实现了在网络中的端到端完全的整数计算。通过引入位移和和加法操作，使得量化模型中的整数值计算同
    全精度模型中的实数计算相对应。而且引入的额外操作的复杂度相对于网络本身的计算而言可以忽略不记。
    最后考虑到卷积网络在移动端的实现，并在卷积的操作中实现了batch norm，relu，bias等操作的融合，
    并入，尽可能减少在存储和计算上不必要的开销，实现卷积网络在移动端CPU的执行效率。
\end{itemize}

\section{未来工作展望}

本文实现了针对于移动端 ARM 设备的整数型Winograd 快速卷积。一定程度上提高了移动端卷积网络的运行
效率。但是，目前的工作仍然有着相当的提升空间。

\begin{itemize}
    \item 本文中优化的Winograd 卷积算法为Winograd卷积算法中尺度较小的 F（2，3） 卷积，该算法
    理论上的加速上限为2.25倍。而Winograd 算法会随着卷积尺度的增大而加速效果更加明显，同时，其
    数值精度也会下降，而在模型参数的数值精度比较低的场景下，即量化网络的场景下，在卷积规模变大
    时，计算的数值稳定性和精度会大幅下降。这里一项重要的原因在于没有找到在卷积尺度变大的场景下
    适合与低精度计算的Winograd算法的形式，即对应的三个变换矩阵。目前主流使用的Winograd 变换
    中的数值的范围在卷积尺度变大时明显变大，而量化网络中数值的范围包括中间特征的范围则是非常有限的。
    所以完全发挥出Winograd卷积在量化场景下的加速效果，还需要找到数值范围相对较小的 Winograd变换
    的形式，克服这一场景下Winograd卷积的数值不稳定性。
    \item 目前的实现中计算的主要负载由NEON实现，但在众多的ARM设备中除了CPU中的SIMD协处理器可以
    用于实现并行计算，很多设备同时还具有GPU支持，而对于移动设备中种类繁多的GPU存在着统一可移植
    的通用接口 - Vulkan。在ARM 设备上使用Vulkan API 在GPU上执行神经网络模型的推理计算将更有效
    的实现，同时更充分的利用设备硬件资源。
\end{itemize}