% !TeX root = ../main.tex

\chapter{卷积操作实现优化}
\label{cha:chapter04}

\section{线程并行化}
前面描述的方法对于计算的并行化处理大多处于指令级别，通过SIMD 矢量处理器的数据并行化处理，
实现指令级别的并行化（Instruction Level Parallelism, ILP）。除此之外，多线程
执行也是实现并行计算的重要手段，称为线程级并行化（Thread Level Parallelism, TLP）。
线程级的并行化处理可以对于处理器内核（core）的计算资源的更为有效的利用，多线程的处理可以
使得superscalar\footnote{超标量体系结构是许多处理器中使用的并行计算方法。 在超标量计算机中，中央处理单元（CPU）管理多个指令流水线，以在一个时钟周期内同时执行多个指令。 这是通过将不同的流水线通过处理器中的多个执行单元来实现的。 为了成功实现超标量架构，CPU的指令获取机制必须智能地检索和委托指令。 否则，可能会发生管道停顿，从而导致执行单元经常处于空闲状态。
} 架构的处理器的执行单元被全部调用，同时通过流水线（pipeline）调度来隐藏
访存所需要的延时（memory latency）。而使用线程并行化的同时也存在着一些额外的需求或者
开销： 首先需要额外的存储满足线程上下文（thread context）的需求，而线程并行化也要求被
优化的程序具有在最基础的指令并行之外的并行度；另外一方面，多线程也会对于内存带宽带来额外的
压力，更多的线程，意味着每个单独的线程所获得的缓存空间会更小。

当前的绝大多数的基于ARM 架构的SoC 都会集成多个 CPU core, 另外ARM 也在计算密集的场景下针对性
的对于处理器添加了SMT(Simultaneous multithreading )支持，比如针对于自动驾驶应用优化的Cortex 
A76AE 微架构。

在实现计算的多线程并行化的过程中，不仅仅要保证被并行的任务中的子任务之间没有依赖，保证子任务
执行的独立性，同时需要避免在多线程执行中可能存在的 False Sharing 和 Cache Line Ping-pong.

\begin{itemize}
  \item 当不同的线程具有程序中未共享的数据，但此数据被映射到共享的缓存行(cache line)时，
  就会发生False Sharing。 例如，假设一个程序具有一个整数数组，其中一个线程执行读取和写
  入具有偶数索引的所有数组条目，而另一个线程执行读取和写入具有奇数索引的条目。 在这种情况下
  ，线程实际上将不会共享数据，但是它们将共享高速缓存行，因为每条高速缓存行都将包含奇数和偶数
  索引值。
  \item 高速缓存行ping-pong是在多个CPU（或内核）之间快速连续传输高速缓存行的效果。
  本质上，如果多个CPU试图在同一高速缓存行中读取和写入数据，则该高速缓存行可能必须快速连续地
  在两个线程之间传输，并且这可能会导致性能显着下降（甚至与单线程相比，性能可能更差）。
\end{itemize}

针对于此，实现多线程处理中需要特别注意以下几点：

\begin{itemize}
    \item 尽可能向同一个CPU 执行写入操作；
    \item 为每个CPU 指定对应的内存；将线程锁定在对应的CPU；
    \item 避免将频繁读写但本身并没有关联的数据放在同一个 Cache Line 中;
\end{itemize}

因此在实现过程中，这里结合本文中的 Winograd 卷积实现设计的空间局部区域的独立性，在特征的输入
变换，GEMM 实现，以及结果的输出变换中，对于整体的图像或者中间特征做了区域性的划分，并在这一层级
上实现多线程的并行，保证每个单独的region 的处理都是独立的，并且向各个处理阶段对应的buffer 输出
处理结果的过程中，各个region 所对应的地址空间避开处于同一cache line的情形。从而保证这一 regional wise
的 Winograd 算法实现在多线程并行下的高效性。


\section{端到端整数计算支持}

在量化计算的量化策略中，本文选择了一种相对简单有效且在实际平台可以具有广泛应用和实现的方案。

矩阵中的每个值均以放射变换的方法（线性变换）通过比例因子和零点值被量化映射到低精度的表示，因此量化域(这里的实现为
8为无符号整数)中的计算可以
直接映射到实数域。比例因子和零点值被矩阵中的多个值所共享，即矩阵中的所有行使用相同的比例因此和零点。
量化矩阵中的值 $x_r$可以通过如下简单的变换方式实现到实数矩阵中的值 $x_q$ 的变换。

\begin{align}
  x_r = a_{scale} (x_q - a_{zero\_point})
\end{align}

这里的比例因子（scale factor） $a_scale$ 一般而言是一个浮点值，而参考在 \cite{Jacob2017QuantizationAT}
对于比例因此的处理，按照上面的实数域和量化域的表示，实数域的值 $x_r, y_r, z_r$ 所对应的量化域中的值分别为
$x_q, y_q, z_q$，三者各自对应的比例因子为 $x_{scale}, y_{scale}, z_{scale}$ , 零点为 $x_{zero}, y_{zero},
 z_{zero}$
那么对应的实数域的乘法的计算可以表示为

\begin{align}
\label{eq:quan_arith}
z_r &= x_r \cdot y_r
z_{scale} \cdot (z_q - z_{zero}) &= (x_{scale} \cdot (x_q - x_{zero})) \cdot (y_{scale} \cdot (y_q - y_{zero})) \\
z_q - z_{zero} &= \frac{x_{scale}\cdot y_{scale}}{z_{scale}} (x_q - x_{zero}) (y_q - y_{zero})\\
z_q &= \frac{x_{scale}\cdot y_{scale}}{z_{scale}} (x_q - x_{zero}) (y_q - y_{zero}) + z_{zero}
\end{align}

这里\ref{eq:quan_arith} 可见实数乘法所对应的量化值乘法，也具备着同实数值和量化值的映射所类似的线性变换形式，
而这里的比例因子 $ M = \frac{x_{scale} y_{scale}}{z_{scale}}$, 按照 \cite{Jacob2017QuantizationAT} 中的经验性
统计可以表示为
\begin{align}
M = 2^{-n} M_0
\end{align}
而其中， $M_0 \in [0.5, 1)$ 且 n 为非负整数。$ M_0$现在很适合表示为定点乘法器（例如，int16或int32取决于硬件）。
例如，如果使用int32，则表示$M_0$的整数是最接近$2^{31}M_0$的int32值。 由于$M_0> 0.5$，因此该值始终至少为$2^{30}$，
因此始终至少具有30位相对精度。 因此，与$M_0$的乘法可以实现为定点乘法。 同时乘以$2^{-n}$可以有效移位来实现

另外，这里的实现中计算操作的输入和网络的权重均为8位无符号整数表示，8位整数的乘法一般会使用32位的累加器，
而在Winograd 卷积实现的将输入由空间域向winograd域 变换过程中，F（2，3） 的Winograd 算法中基本只涉及加减操作，
在这一过程中将输入的无符号8位整数转换为16位带符号整数做处理，并且在后续的矩阵乘法操作中实现中使用 32 位的累加器,
每次乘累加操作中，将16位整数乘法的结果widen 到32位再加到32位的累加器中。而在一般的基于GEMM的量化卷积实现中，
累加结束后，会再次通过量化，将32位 的整数表示转换位8位整数的表示，这一过程可以称为再量化（re-quantization ）或者后累加量化（post-accumulation quantization）
而Winograd 卷积的实现中，乘累加操作结束之后，还需要执行输出变换操作，将Winograd 域中的矩阵乘法结果转换回空间域,
此后再执行量化，并将量化之后的8位整数输出，从而降低对于内存带宽的压力和缓存占用。

\section{卷积相关操作的融合}

此外，现在通用的卷积网络中，卷积操作之后通常还带有bias，而在卷积操作之后还通常会紧随着Batch Normalization 操作
和 Relu 激活函数，这一流程构成了卷积网络中常用的一大范式即，Conv（+ Bias）-> BatchNorm -> Relu。相比于卷积操作
而言添加Bias，并对输出的特征作Batch Normalization 和 relu激活本身从计算复杂度角度而言，都是不值一提的，但是在
ARM 设备的这种嵌入市场景下，将这几个流程作为单独的操作在模型的运行时顺序执行，则是需要额外的存储消耗的（memory 
footprint）。每次执行单个操作的过程中，都需要从memory系统中读入上一操作输出的特征，并且把简单计算操作之后的结果
再写入memory，这同在嵌入式场景计算和存储资源受限的条件下需要最大化计算/访存操作的比例的优化目标是相悖的。而注意到
这些后续的操作实际上都是可以转化为区域性（regional wise）inplace 的操作的，特别是Batch Normalization 在模型训练
结束之后，单纯作inference的过程中是可以和卷积操作实现融合的。以下简述Batch Normalization 同卷积的融合的过程。

对于Batch Norm 的输入特征 $x$, Batch Norm 本身的参数 $\gamma$, $\beta$, 以及训练过程中对于输入特征的统计量
（exponential moving average）$\mu$ $\sigma$. 操作对应的输出则为 $\tilde{x}$，Batch Norm 操作的形式如下：

\begin{align}
\label{eq:bn}
\tilde{x_i} = \gamma \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta
\end{align}

而这一操作可以通过 1x1 卷积实现。给定一个输入特征 F，其data layout 为 $C \times H \times W$, 其对应的Batch Norm的
结果$\hat{F}$可通过计算每个空间位置$i, j$的如下矩阵-矢量乘法获得：

\begin{equation}
\label{eq:bn_matvec}
	\begin{pmatrix}
		\hat{F_{1,i,j}} \\
		\hat{F_{2,i,j}} \\
		\vdots \\
		\hat{F_{C,i,j}}
	\end{pmatrix}
	=
	\begin{pmatrix}
		\frac{\gamma_{1}{\sqrt{\sigma_{1}^2 + \epsilon}}} & 0 & \dots & 0 \\
		0 & \frac{\gamma_{2}{\sqrt{\sigma_{2}^2 + \epsilon}}}  & \dots & 0 \\
		\vdots \\
	        0 & 0 & \dots & \frac{\gamma_{C}}{\sqrt{\sigma_{C}^2 + \epsilon}}
	\end{pmatrix}
	+
	\begin{pmatrix}
		F_{1,i,j} \\
		F_{2,i,j} \\
		\vdots \\
		F_{C,i,j}
	\end{pmatrix}
	+ 
	\begin{pmatrix}
		\beta_{1} - \gamma_1 \frac{\mu_1}{\sqrt{\sigma_1^2 + \epsilon}}\\
		\beta_{2} - \gamma_2 \frac{\mu_2}{\sqrt{\sigma_2^2 + \epsilon}}\\
		\vdots \\
		\beta_{C} - \gamma_C \frac{\mu_C}{\sqrt{\sigma_C^2 + \epsilon}}
	\end{pmatrix}
\end{equation}

而Batch Norm操作往往又紧随卷积操作，于是可以将Batch Norm操作融合入卷积操作，将上述的batch norm的矩阵表示\label{eq:bn_matvec}
表示为 $\hat{F} = W_{bn} \cdot F + b_{bn}$, 其中 $W_{bn} \in R^{CxC}, b_{bn} \in R^C$, 而嵌入Batch Norm 
操作前继的卷积操作之后，这一计算过程则为：
\begin{align}
\hat{f_{i,j}} = W_{bn} \cdot (W_{conv} \cdot f_{i,j} + b_{conv}) + b_{bn}
\end{align}

于是卷积和Batch Norm 两个操作可以通过一个权重为 $W = W_{bn} \cdot W_{conv}$, Bias 为 $b = W_{bn} \cdot b_{conv} + b_{bn}$
的卷积操作来替代。

除此之外，对卷积的添加Bias 和relu激活，则可以在Winograd卷积的每个子区域的输出变换过程中，在重量化之前，
in-place的实现添加Bias，而在重量化之后，通过输出值截断（output clamping），实现诸如 Relu或者 Relu6 这样
的简单的激活函数，从而减少模型运行时对于内存的开销。

\section{NEON 计算指令优化}

到目前实现为止，在ARM 处理器上最为广泛得以应用的并行计算资源便是NEON，这一技术自ARMv7-A ISA起成为ARM芯片
的处理计算密集型应用的最为通用的主力解决方案，而ARM 也在ARM v8.2A指令架构中提出了对于NEON的矢量计算的扩展
SVE(Scalable Vector Extension)，然而作为一项可选的扩展，目前的通用ARM计算设备中几乎没有支持这一特性(富士通
的下一代超算使用ARM架构，支持SVE)。另外例如高通这样的集成电路设计者会在SoC方案中添加一些专门的计算单元，比如
高通的Hexagon DSP针对性的优化了对于量化计算的支持，HTA（Hexagon Tensor Accelerator）, HVX(Hexagon Vector 
eXtension) 的支持，使得在这种设备上的on device 模型推理计算有了额外的优化途径，并减轻了CPU的压力。同时NVIDIA
也为其面向移动端的ARM 架构芯片提供了GPU 和Cuda 支持。但是这些额外的专门硬件的支持网络模型推理计算的方案，局限性
也是显而易见的，即受到硬件本身的局限，不具备通用性。在实现可移植，强适应性，高效率的计算密集应用下，NEON还是
目前最优的选择。

在细节上实现高效的NEON指令的调用以及调度对于在ARM 架构设备上的高效智能计算具有着至关重要的意义。在实现量化的
快速卷积过程中，本作遵循了以下优化原则：

\begin{itemize}
    \item 连续的计算指令之间不得存在数据依赖。某些计算指令，比如乘累加，的操作延时（latency）比较高, 为了减少指令等待时间，
    需要避免将当前指令的目标寄存器用作下一条指令的源寄存器。在实现中，这里将 vld(数据加载)， vmlal（乘累加），st（数据写出）
    等操作在调度的过程中实现第一阶段通过多个vld 指令加载各项所需的数据，第二阶段 通过乘累加操作计算相互独立的矢量计算，这里
    每个乘累加操作需要有各自独立的累加器，否则累加过程会存在data dependence 造成指令stall。第三 阶段再将乘累加的结果写出。
    \item NEON/FPU是一个独立的处理单元，Load/Store Unit也是一个独立处理单元，两个单元可以并行执行。Load/Store Unit可以在
    加载到第一个数据的时候立即把数据forward给NEON/FPU，这样在只有一条VLDM指令时，只需要引入1个CPU cycles的延迟了。
    这就提示我们通过合理的打散VLDM指令并和NEON/FPU指令交织（interleave），可以提升指令执行的并行度，并继 续提升软件的性能。
    \item NEON指令执行计算的过程中不得出现条件分支。NEON指令集中没有分支跳转指令。 当需要跳转时，使用ARM的跳转指令。 在ARM
    处理器中，分支预测技术被广泛使用。 但是一旦分支预测失败，那么惩罚就会很高。 因此，最好避免使用跳转说明。
\end{itemize}

\section{Winograd 算法数值稳定性}

尽管Winograd 算法是现已知的在计算复杂度而言最优的卷积算法， 然而 Winograd 卷积算法具有着数值
计算不稳定的特质。在卷积的尺度相对比较小（比如F(2,3), F(4, 3)），并且参与运算的数值为单精度或
者双精度浮点数时，Winograd 卷积的结果仍然是相当精确的，但是当卷积的尺度变大，或者参数计算的数值
精度降低时，这一情况却不容乐观了。这也限制了Winograd 卷积的适用范围，在卷积核或者卷积操作输入的
子块的尺度较大的情形下，Winograd卷积的精确性便会有比较明显的损失。 Winograd 卷积计算的精确性
可以通过找出更加合适的Winograd 算法的导出式有关，即通过 Toom-Cook 算法或者CRP理论选择合适的
interpolation points导出对应的输入变化，权重变换和输出变换矩阵。 这里需要说明的一点是，Winograd 
卷积的数值不稳定性，带来的只是一种边际数值误差（marginal error），因此，Winograd 卷积在很多情形
下只是应用于模型 的推理阶段，
即网络在训练的过程中使用常规的卷积算法，而在模型前向推理的过程中，是完全可以将对应的满足条件的
卷积操作可以替换为 Winograd 卷积算法。

表 \ref{tbl:winograd_acc} 中对比了不同尺度的Winograd 卷积算法在不同精度的数据表示下的准确度及数值
稳定性，这里以直接卷积算法的准确率作为对照，可见对于输出尺度大于2 的 Winograd 卷积在low precision 
的场景下在对应视觉任务上的准确率会大幅下降，而这里指的Winograd 卷积指的是在 \cite{Lavin2015FastAF}
以及附带的Toom Cook 方法代码中所导出Winograd 算法形式。究其原因在于，在Winograd 卷积的输出尺度较大
时, 如\ref{eq:winograd_f43} 可见，在变换矩阵 $A^T, G, B^T$ 中对应的数值的范围会变大，并且注意，在
卷积神经网络中常用的2D 卷积中，将其转换为整数型计算时，权重变换矩阵 G 需要扩大 24 倍，则卷积计算过程
中，至少要保证在 $\pm24^2$ 范围内数据的表示和计算数值精度 。

\begin{table}[]
\centering
\caption{ResNet 18 在不同尺度和不同精度的Winograd 卷积算法下的CIFAR-10 分类准确率}
\begin{tabular}{llll}
\hline
\multicolumn{1}{|l|}{}                 & \multicolumn{1}{l|}{32 bit} & \multicolumn{1}{l|}{16 bit} & \multicolumn{1}{l|}{8 bit} \\ \hline
\multicolumn{1}{|l|}{Direct  Conv}     & \multicolumn{1}{l|}{93.16}  & \multicolumn{1}{l|}{93.60}  & \multicolumn{1}{l|}{93.22} \\ \hline
\multicolumn{1}{|l|}{Winograd F(2, 3)} & \multicolumn{1}{l|}{93.16}  & \multicolumn{1}{l|}{93.48}  & \multicolumn{1}{l|}{93.21} \\ \hline
\multicolumn{1}{|l|}{Winograd F(4, 3)} & \multicolumn{1}{l|}{93.14}  & \multicolumn{1}{l|}{19.25}  & \multicolumn{1}{l|}{17.36} \\ \hline
\multicolumn{1}{|l|}{Winograd F(6, 3)} & \multicolumn{1}{l|}{93.11}  & \multicolumn{1}{l|}{11.41}  & \multicolumn{1}{l|}{10.95} \\ \hline
\end{tabular}
\label{tbl:winograd_acc}
\end{table}
\begin{align}
\label{eq:winograd_f43}
  A^T = 
  \begin{pmatrix}
      1 & 1 & 1 &  1 &  1 &  0\\
      0 & 1 & -1&  2 &  -2&  0\\
      0 & 1 & 1 &  4 &  4 &  0\\
      0 & 1 & -1&  8 &  -8&  1
  \end{pmatrix}
  G = 
  \begin{pmatrix}
    \frac{1}{4} & 0 & 0 \\
    -\frac{1}{6} & -\frac{1}{6} & -\frac{1}{6} \\
    -\frac{1}{6} & \frac{1}{6} & -\frac{1}{6} \\
    \frac{1}{24} & \frac{1}{12} & \frac{1}{6} \\
    \frac{1}{24} & -\frac{1}{12} & \frac{1}{6} \\
    0 & 0 & 1
  \end{pmatrix}
  B^T =
  \begin{pmatrix}
    4  & 0 &  -5 & 0  &  1&  0\\
    0  & -4&  -4 & 1  &  1&  0\\
    0  & 4 &  -4 & -1 &  1&  0\\
    0  & -2&  -1 & 2  &  1&  0\\
    0  & 2 &  -1 & -2 &  1&  0\\
    0  & 4 &  0  & -5 &  0&  1
  \end{pmatrix}
\end{align}

\section{实验验证}

这一部分验证本文中实现的整数Winograd 快速卷积在嵌入式设别上的有效性，
包括
\begin{itemize}
  \item 针对单个卷积操作本身的执行效率，测量不同尺度规模的卷积输入下
    \begin{itemize}
        \item 该卷积实现同对应的全精度Winograd快速卷积的加速效果, 包括执行效率和内存开销(对照组为NNPACK实现)
        \item 该卷积实现同基于GEMM卷积方法的整数卷积效率对比(对照组为QNNPACK实现)
    \end{itemize}
  \item 针对于由此卷积操作构成的卷积网络在特定的视觉任务上的的执行性能和效率
    \begin{itemize}
        \item 同全精度网络的执行效率和准确率作对比加速效果存储开销和数值精度
        \item 同支持量化卷积计算的模型推理框架（TensorFlow lite， PyTorch Mobile）对比实现的准确率与加速效果
    \end{itemize}

\end{itemize}
