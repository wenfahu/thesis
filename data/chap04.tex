% !TeX root = ../main.tex

\chapter{量化卷积操作在嵌入式设备的实现优化}
\label{cha:chapter04}

前面的章节已经对于本文中针对于加速卷积计算所提出的主要的方法，包括多通道的局部区域化Winograd 卷积
以及中小规模量化矩阵的乘法，以下将主要针对于前文所提出的量化卷积操作作为卷积神经网络中的组成部分，
分别从指令并行优化，线程并行优化，支持端到端整数计算的量化/反量化（quantize/dequantize）策略以及
网络部署中的卷积相关的操作融合，展开描述。并将这一卷积实现集成到具体的卷积网络中，验证其对于卷积
网络的加速效果。

\section{NEON 计算指令并行优化}

到目前实现为止，在ARM 处理器上最为广泛得以应用的并行计算资源便是NEON，这一技术自ARMv7-A ISA起成为ARM芯片
的处理计算密集型应用的最为通用的主力解决方案，而ARM 也在ARM v8.2A指令架构中提出了对于NEON的矢量计算的扩展
SVE(Scalable Vector Extension)，然而作为一项可选的扩展，目前的通用ARM计算设备中几乎没有支持这一特性(富士通
的下一代超算使用ARM架构，支持SVE)。另外例如高通这样的集成电路设计者会在SoC方案中添加一些专门的计算单元，比如
高通的Hexagon DSP针对性的优化了对于量化计算的支持，HTA（Hexagon Tensor Accelerator）, HVX(Hexagon Vector 
eXtension) 的支持，使得在这种设备上的on device 模型推理计算有了额外的优化途径，并减轻了CPU的压力。同时NVIDIA
也为其面向移动端的ARM 架构芯片提供了GPU 和Cuda 支持。但是这些额外的专门硬件的支持网络模型推理计算的方案，局限性
也是显而易见的，即受到硬件本身的局限，不具备通用性。在实现可移植，强适应性，高效率的计算密集应用下，NEON还是
目前最优的选择。

在细节上实现高效的NEON指令的调用以及调度对于在ARM 架构设备上的高效智能计算具有着至关重要的意义。在实现量化的
快速卷积过程中，本作遵循了以下优化原则：

\begin{itemize}
    \item 连续的计算指令之间不得存在数据依赖。某些计算指令，比如乘累加，的操作延时（latency）比较高, 为了减少指令等待时间，
    需要避免将当前指令的目标寄存器用作下一条指令的源寄存器。在实现中，这里将 vld(数据加载)， vmlal（乘累加），st（数据写出）
    等操作在调度的过程中实现第一阶段通过多个vld 指令加载各项所需的数据，第二阶段 通过乘累加操作计算相互独立的矢量计算，这里
    每个乘累加操作需要有各自独立的累加器，否则累加过程会存在data dependence 造成指令stall。第三 阶段再将乘累加的结果写出。
    \item NEON/FPU是一个独立的处理单元，Load/Store Unit也是一个独立处理单元，两个单元可以并行执行。Load/Store Unit可以在
    加载到第一个数据的时候立即把数据forward给NEON/FPU，这样在只有一条VLDM指令时，只需要引入1个CPU cycles的延迟了。
    这就提示我们通过合理的打散VLDM指令并和NEON/FPU指令交织（interleave），可以提升指令执行的并行度，并继 续提升软件的性能。
    \item NEON指令执行计算的过程中不得出现条件分支。NEON指令集中没有分支跳转指令。 当需要跳转时，使用ARM的跳转指令。 在ARM
    处理器中，分支预测技术被广泛使用。 但是一旦分支预测失败，那么惩罚就会很高。 因此，最好避免使用跳转说明。
\end{itemize}

\section{线程并行化}
前面描述的方法对于计算的并行化处理大多处于指令级别，通过SIMD 矢量处理器的数据并行化处理，
实现指令级别的并行化（Instruction Level Parallelism, ILP）。除此之外，多线程
执行也是实现并行计算的重要手段，称为线程级并行化（Thread Level Parallelism, TLP）。
线程级的并行化处理可以对于处理器内核（core）的计算资源的更为有效的利用，多线程的处理可以
使得superscalar\footnote{超标量体系结构是许多处理器中使用的并行计算方法。 在超标量计算机中，中央处理单元（CPU）管理多个指令流水线，以在一个时钟周期内同时执行多个指令。 这是通过将不同的流水线通过处理器中的多个执行单元来实现的。 为了成功实现超标量架构，CPU的指令获取机制必须智能地检索和委托指令。 否则，可能会发生pipeline stall，从而导致执行单元经常处于空闲状态。
} 架构的处理器的执行单元被全部调用，同时通过流水线（pipeline）调度来隐藏
访存所需要的延时（memory latency）。而使用线程并行化的同时也存在着一些额外的需求或者
开销： 首先需要额外的存储满足线程上下文（thread context）的需求，而线程并行化也要求被
优化的程序具有在最基础的指令并行之外的并行度；另外一方面，多线程也会对于内存带宽带来额外的
压力，更多的线程，意味着每个单独的线程所获得的缓存空间会更小。

当前的绝大多数的基于ARM 架构的SoC 都会集成多个 CPU core, 另外ARM 也在计算密集的场景下针对性
的对于处理器添加了SMT(Simultaneous multithreading )支持，比如针对于自动驾驶应用优化的Cortex 
A76AE 微架构。

在实现计算的多线程并行化的过程中，不仅仅要保证被并行的任务中的子任务之间没有依赖，保证子任务
执行的独立性，同时需要避免在多线程执行中可能存在的 False Sharing 和 Cache Line Ping-pong.

\begin{itemize}
  \item 当不同的线程具有程序中未共享的数据，但此数据被映射到共享的缓存行(cache line)时，
  就会发生False Sharing。 例如，假设一个程序具有一个整数数组，其中一个线程执行读取和写
  入具有偶数索引的所有数组条目，而另一个线程执行读取和写入具有奇数索引的条目。 在这种情况下
  ，线程实际上将不会共享数据，但是它们将共享高速缓存行，因为每条高速缓存行都将包含奇数和偶数
  索引值。
  \item 高速缓存行ping-pong是在多个CPU（或内核）之间快速连续传输高速缓存行的效果。
  本质上，如果多个CPU试图在同一高速缓存行中读取和写入数据，则该高速缓存行可能必须快速连续地
  在两个线程之间传输，并且这可能会导致性能显着下降（甚至与单线程相比，性能可能更差）。
\end{itemize}

针对于此，实现多线程处理中需要特别注意以下几点：

\begin{itemize}
    \item 尽可能向同一个CPU 执行写入操作；
    \item 为每个CPU 指定对应的内存；将线程锁定在对应的CPU；
    \item 避免将频繁读写但本身并没有关联的数据放在同一个 Cache Line 中;
\end{itemize}

因此在实现过程中，这里结合本文中的 Winograd 卷积实现设计的空间局部区域的独立性，在特征的输入
变换，GEMM 实现，以及结果的输出变换中，对于整体的图像或者中间特征做了区域性的划分，并在这一层级
上实现多线程的并行，保证每个单独的region 的处理都是独立的，并且向各个处理阶段对应的buffer 输出
处理结果的过程中，各个region 所对应的地址空间避免处于同一cache line的情形。从而保证这一 regional wise
的 Winograd 算法实现在多线程并行下的高效性。


\section{端到端整数计算支持}

在量化计算的量化策略中，本文选择了一种相对简单有效且在实际平台可以具有广泛应用和实现的方案。

矩阵中的每个值均以放射变换的方法（线性变换）通过比例因子和零点值被量化映射到低精度的表示，因此量化域(这里的实现为
8为无符号整数)中的计算可以
直接映射到实数域。比例因子和零点值被矩阵中的多个值所共享，即矩阵中的所有行使用相同的比例因子和零点。
量化矩阵中的值 $x_r$可以通过如下简单的变换方式实现到实数矩阵中的值 $x_q$ 的变换。

\begin{align}
  x_r = a_{scale} (x_q - a_{zero\_point})
\end{align}

这里的比例因子（scale factor） $a_scale$ 一般而言是一个浮点值，而参考在 \cite{Jacob2017QuantizationAT}
对于比例因子的处理，按照上面的实数域和量化域的表示，实数域的值 $x_r, y_r, z_r$ 所对应的量化域中的值分别为
$x_q, y_q, z_q$，三者各自对应的比例因子为 $x_{scale}, y_{scale}, z_{scale}$ , 零点为 $x_{zero}, y_{zero},
 z_{zero}$
那么对应的实数域的乘法的计算可以表示为

\begin{align}
\label{eq:quan_arith}
z_r &= x_r \cdot y_r\\
z_{scale} \cdot (z_q - z_{zero}) &= (x_{scale} \cdot (x_q - x_{zero})) \cdot (y_{scale} \cdot (y_q - y_{zero})) \\
z_q - z_{zero} &= \frac{x_{scale}\cdot y_{scale}}{z_{scale}} (x_q - x_{zero}) (y_q - y_{zero})\\
z_q &= \frac{x_{scale}\cdot y_{scale}}{z_{scale}} (x_q - x_{zero}) (y_q - y_{zero}) + z_{zero}
\end{align}

这里\ref{eq:quan_arith} 可见实数乘法所对应的量化值乘法，也具备着同实数值和量化值的映射所类似的线性变换形式，
而这里的比例因子 $ M = \frac{x_{scale} y_{scale}}{z_{scale}}$, 按照 \cite{Jacob2017QuantizationAT} 中的经验性
统计可以表示为
\begin{align}
M = 2^{-n} M_0
\end{align}
而其中， $M_0 \in [0.5, 1)$ 且 n 为非负整数。$ M_0$现在很适合表示为定点乘法器（例如，int16或int32取决于硬件）。
例如，如果使用int32，则表示$M_0$的整数是最接近$2^{31}M_0$的int32值。 由于$M_0> 0.5$，因此该值始终至少为$2^{30}$，
因此始终至少具有30位相对精度。 因此，与$M_0$的乘法可以实现为定点乘法。 同时乘以$2^{-n}$可以有效移位来实现

另外，这里的实现中计算操作的输入和网络的权重均为8位无符号整数表示，8位整数的乘法一般会使用32位的累加器，
而在Winograd 卷积实现的将输入由空间域向winograd域 变换过程中，F（2，3） 的Winograd 算法中基本只涉及加减操作，
在这一过程中将输入的无符号8位整数转换为16位带符号整数做处理，并且在后续的矩阵乘法操作中实现中使用 32 位的累加器,
每次乘累加操作中，将16位整数乘法的结果widen 到32位再加到32位的累加器中。而在一般的基于GEMM的量化卷积实现中，
累加结束后，会再次通过量化，将32位 的整数表示转换为8位整数的表示，这一过程可以称为再量化（re-quantization ）或者后累加量化（post-accumulation quantization）
而Winograd 卷积的实现中，乘累加操作结束之后，还需要执行输出变换操作，将Winograd 域中的矩阵乘法结果转换回空间域,
此后再执行量化，并将量化之后的8位整数输出，从而降低对于内存带宽的压力和缓存占用。

\section{卷积相关操作的融合}

此外，现在通用的卷积网络中，卷积操作之后通常还带有bias，而在卷积操作之后还通常会紧随着Batch Normalization 操作
和 Relu 激活函数，这一流程构成了卷积网络中常用的一大范式即，Conv（+ Bias）$\to$ BatchNorm $\to$ Relu。相比于卷积操作
而言添加Bias，并对输出的特征作Batch Normalization 和 relu激活本身从计算复杂度角度而言，都是不值一提的，但是在
ARM 设备的这种嵌入式场景下，将这几个流程作为单独的操作在模型的运行时顺序执行，则是需要额外的存储消耗的（memory 
footprint）。每次执行单个操作的过程中，都需要从memory系统中读入上一操作输出的特征，并且把简单计算操作之后的结果
再写入memory，这同在嵌入式场景计算和存储资源受限的条件下需要最大化计算/访存操作的比例的优化目标是相悖的。而注意到
这些后续的操作实际上都是可以转化为区域性（regional wise）inplace 的操作的，特别是Batch Normalization 在模型训练
结束之后，单纯作inference的过程中是可以和卷积操作实现融合的。以下简述Batch Normalization 同卷积的融合的过程。

对于Batch Norm 的输入特征 $x$, Batch Norm 本身的参数 $\gamma$ 和$\beta$, 以及训练过程中对于输入特征的统计量
（exponential moving average）$\mu$ $\sigma$. 操作对应的输出则为 $\tilde{x}$，Batch Norm 操作的形式如下：

\begin{align}
\label{eq:bn}
\tilde{x_i} = \gamma \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta
\end{align}

而这一操作可以通过 1x1 卷积实现。给定一个输入特征 F，其data layout 为 $C \times H \times W$, 其对应的Batch Norm的
结果$\hat{F}$可通过计算每个空间位置$i, j$的如下矩阵-矢量乘法获得：

\begin{equation}
\label{eq:bn_matvec}
	\begin{pmatrix}
		\hat{F_{1,i,j}} \\
		\hat{F_{2,i,j}} \\
		\vdots \\
		\hat{F_{C,i,j}}
	\end{pmatrix}
	=
	\begin{pmatrix}
		\frac{\gamma_{1}{\sqrt{\sigma_{1}^2 + \epsilon}}} & 0 & \dots & 0 \\
		0 & \frac{\gamma_{2}{\sqrt{\sigma_{2}^2 + \epsilon}}}  & \dots & 0 \\
		\vdots \\
	        0 & 0 & \dots & \frac{\gamma_{C}}{\sqrt{\sigma_{C}^2 + \epsilon}}
	\end{pmatrix}
	+
	\begin{pmatrix}
		F_{1,i,j} \\
		F_{2,i,j} \\
		\vdots \\
		F_{C,i,j}
	\end{pmatrix}
	+ 
	\begin{pmatrix}
		\beta_{1} - \gamma_1 \frac{\mu_1}{\sqrt{\sigma_1^2 + \epsilon}}\\
		\beta_{2} - \gamma_2 \frac{\mu_2}{\sqrt{\sigma_2^2 + \epsilon}}\\
		\vdots \\
		\beta_{C} - \gamma_C \frac{\mu_C}{\sqrt{\sigma_C^2 + \epsilon}}
	\end{pmatrix}
\end{equation}

而Batch Norm操作往往又紧随卷积操作，于是可以将Batch Norm操作融合入卷积操作，将上述的batch norm的矩阵表示\label{eq:bn_matvec}
表示为 $\hat{F} = W_{bn} \cdot F + b_{bn}$, 其中 $W_{bn} \in R^{CxC}, b_{bn} \in R^C$, 而嵌入Batch Norm 
操作前继的卷积操作之后，这一计算过程则为：
\begin{align}
\hat{f_{i,j}} = W_{bn} \cdot (W_{conv} \cdot f_{i,j} + b_{conv}) + b_{bn}
\end{align}

于是卷积和Batch Norm 两个操作可以通过一个权重为 $W = W_{bn} \cdot W_{conv}$, Bias 为 $b = W_{bn} \cdot b_{conv} + b_{bn}$
的卷积操作来替代。

除此之外，对卷积的添加Bias 和relu激活，则可以在Winograd卷积的每个子区域的输出变换过程中，在重量化之前，
in-place的实现添加Bias，而在重量化之后，通过输出值截断（output clamping），实现诸如 Relu或者 Relu6 这样
的简单的激活函数，从而减少模型运行时对于内存的开销。



\section{卷积网络加速实验验证}

为将本文实现的卷积算法同卷积神经网络推理框架整合集成，并且验证其对于卷积神经网络推理在ARM Cortex A设备上加速的有效性， 本节针对于在移动端高效实现的卷积网络，在ARM Cortex A设备上运行集成了本文局部区域性多通道Winograd 卷积算法的卷积网络，以下从实验环境，实验设计和结果分析展开介绍。

\subsection{实验环境与实验设计}
\begin{table}[]
  \centering
  \caption{ResNet18 网络总体结构}
  \begin{tabular}{ccc}
    \toprule
    结构名称 & 输出尺寸 & 结构 \\
    \midrule
    conv1 & 112x112 & 7x7, 64, stride 2 \\
    block1 & 56x56 & $ \begin{bmatrix} 3x3, & 64 \\  3x3, & 64 \end{bmatrix} x 2 $ \\ 
    \\
    block2 & 28x28 & $ \begin{bmatrix} 3x3, & 128 \\  3x3, & 128 \end{bmatrix} x 2 $ \\
    \\
    block3 & 14x14 & $ \begin{bmatrix} 3x3, & 256 \\  3x3, & 256 \end{bmatrix} x 2 $ \\
    \\
    block4 & 7x7 & $ \begin{bmatrix} 3x3, & 512 \\  3x3, & 512 \end{bmatrix} x 2 $ \\
    \bottomrule
  \end{tabular}
  \label{tbl:resnet_arch}
\end{table}


这里的硬件环境配置同第三章\ref{cha:chapter03} 一致。本节实验中，使用ResNet18 作为验证卷积网络加速效果的模型。这里的对比实现同样为TensorFlow Lite中量化卷积的Im2col 卷积实现。本文将这里实现的快速卷积方法集成入PyTorch，实验结果由在PyTorch上运行模型的时间为准。本文实现所作用的有效对象为网络结构中的3x3， stride 为 1 的卷积。

ResNet18 结构中包含多个Residual Block，可参见\ref{tbl:resnet_arch}本节将针对于各个卷积Residual Block 的加速效果和网络整体的加速效果展开实验与分析。

\subsection{实验结果与分析}

表\ref{tbl:conv_speedup} 中显示了在ResNet18 中的各个卷积子结构的加速效果以及网络整体的加速效果。可见本文提出的局部区域多通道卷积算法对于在实际网络中的卷积计算加速有着显著的提升，同时对于移动端所使用的卷积神经网络在边缘设备上的运行效率提升也具有着明显的意义。


\begin{table}[]
\centering
\caption{ResNet18 网络及子结构加速效果}
\begin{tabular}{ccccc}
  \toprule
  结构   & Im2Col(ms) & 本文(ms) & 加速效果 \\
  \midrule
  conv1  & 51.047  & 31.529 & 1.619 \\
  block1  &  114.559 & 65.675 & 1.744x \\
  block2  & 95.723 & 76.505 & 1.251 \\
  block3  & 86.587 & 70.223 & 1.233 \\
  block4 & 95.916 & 81.382 & 1.179 \\
  整体网络& 446.786 & 326.678  & 1.368 \\
  \bottomrule
\end{tabular}
\label{tbl:conv_speedup}
\end{table}
\iffalse
\section{实验验证}

这一部分验证本文中实现的整数Winograd 快速卷积在嵌入式设备上的有效性，
包括
\begin{itemize}
  \item 针对单个卷积操作本身的执行效率，测量不同尺度规模的卷积输入下
    \begin{itemize}
        \item 该卷积实现同对应的全精度Winograd快速卷积的加速效果, 包括执行效率和内存开销(对照组为NNPACK实现)
        \item 该卷积实现同基于GEMM卷积方法的整数卷积效率对比(对照组为QNNPACK实现)
    \end{itemize}
  \item 针对于由此卷积操作构成的卷积网络在特定的视觉任务上的的执行性能和效率
    \begin{itemize}
        \item 同全精度网络的执行效率和准确率作对比加速效果存储开销和数值精度
        \item 同支持量化卷积计算的模型推理框架（TensorFlow lite， PyTorch Mobile）对比实现的准确率与加速效果
    \end{itemize}

\end{itemize}
\fi
